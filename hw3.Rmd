---
title: "hw3"
author: "min"
date: "2022-10-13"
output: github_document
---
# problem 1

## preparation
```{r}
library(tidyverse)
library(ggridges)
library(patchwork)
library(p8105.datasets)
data("instacart")
```

#### Introduce the data
```{r}
instacart = 
  instacart %>% 
  as_tibble(instacart)

instacart
```
*The data has 15 columns (variables) and 1384617 rows (observations). The variables starts with order_id, product_id for identification and variables like product_name, aisle, departments specify the goods. For example, product_id 49302 is Bulgarian Yogurt, which is in aisle yogurt department dairy eggs.*

In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` different products in `r instacart %>% select(order_id) %>% distinct %>% count` different orders from `r instacart %>% select(user_id) %>% distinct %>% count` different users.


#### answer the questions

count aisles
```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```
*There are 134 aisles, and fresh vegetables is where the most items ordered from*

plot of the number of items ordered in each aisle, only in which more than 10000 items ordered
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle,y = n)) + 
  geom_point() + 
  labs(title = "number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Table of the three most popular items in aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Table of the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered everyday
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow + 1, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

# problem 2

## tidy the data
```{r}
acc_data = read.csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  rename(day_of_the_week = day, day = day_id) %>% 
  pivot_longer(activity_1:activity_1440,
               names_to = "minute_from_midnight",
               names_prefix = "activity.",
               values_to = "activity_counts") %>% 
  mutate(minute_from_midnight = as.numeric(minute_from_midnight)) %>% 
  mutate(weekday_vs_weekend = 
           ifelse(day_of_the_week == c("Saturday","Sunday"),"weekend","weekday"))

acc_data
```


## aggregate table
```{r}
acc_data %>% 
  group_by(week, day_of_the_week) %>% 
  summarize(total = sum(activity_counts)) %>% 
  pivot_wider(names_from = day_of_the_week,
              values_from = total) %>% 
  select(week, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday)

acc_data %>% 
  group_by(day, minute_from_midnight,weekday_vs_weekend) %>% 
  summarize(total = sum(activity_counts)) %>% 
  arrange(desc(total)) %>% 
  head(20)
```
*There is no apparent trend in the first table, but in the second, we can see it tends to have higher activity counts in weekdays, and it is more likely to have higher activity counts at around 1170 minutes from midnight.*

## plot
```{r}
acc_data %>% 
  ggplot(aes(x = minute_from_midnight,y = activity_counts, color = week)) + 
  geom_point()
```

